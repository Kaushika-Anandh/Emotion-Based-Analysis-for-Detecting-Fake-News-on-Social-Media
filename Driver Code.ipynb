{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "4e1dec64",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2023-11-20 02:47:12.854121: I tensorflow/core/util/port.cc:110] oneDNN custom operations are on. You may see slightly different numerical results due to floating-point round-off errors from different computation orders. To turn them off, set the environment variable `TF_ENABLE_ONEDNN_OPTS=0`.\n",
      "2023-11-20 02:47:12.906101: I tensorflow/core/platform/cpu_feature_guard.cc:183] This TensorFlow binary is optimized to use available CPU instructions in performance-critical operations.\n",
      "To enable the following instructions: SSE3 SSE4.1 SSE4.2 AVX, in other operations, rebuild TensorFlow with the appropriate compiler flags.\n",
      "2023-11-20 02:47:24.366118: I tensorflow/compiler/xla/stream_executor/cuda/cuda_gpu_executor.cc:995] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero. See more at https://github.com/torvalds/linux/blob/v6.0/Documentation/ABI/testing/sysfs-bus-pci#L344-L355\n",
      "2023-11-20 02:47:24.372383: I tensorflow/compiler/xla/stream_executor/cuda/cuda_gpu_executor.cc:995] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero. See more at https://github.com/torvalds/linux/blob/v6.0/Documentation/ABI/testing/sysfs-bus-pci#L344-L355\n",
      "2023-11-20 02:47:24.372557: I tensorflow/compiler/xla/stream_executor/cuda/cuda_gpu_executor.cc:995] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero. See more at https://github.com/torvalds/linux/blob/v6.0/Documentation/ABI/testing/sysfs-bus-pci#L344-L355\n",
      "2023-11-20 02:47:24.373984: I tensorflow/compiler/xla/stream_executor/cuda/cuda_gpu_executor.cc:995] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero. See more at https://github.com/torvalds/linux/blob/v6.0/Documentation/ABI/testing/sysfs-bus-pci#L344-L355\n",
      "2023-11-20 02:47:24.374166: I tensorflow/compiler/xla/stream_executor/cuda/cuda_gpu_executor.cc:995] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero. See more at https://github.com/torvalds/linux/blob/v6.0/Documentation/ABI/testing/sysfs-bus-pci#L344-L355\n",
      "2023-11-20 02:47:24.374271: I tensorflow/compiler/xla/stream_executor/cuda/cuda_gpu_executor.cc:995] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero. See more at https://github.com/torvalds/linux/blob/v6.0/Documentation/ABI/testing/sysfs-bus-pci#L344-L355\n",
      "2023-11-20 02:47:24.454778: I tensorflow/compiler/xla/stream_executor/cuda/cuda_gpu_executor.cc:995] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero. See more at https://github.com/torvalds/linux/blob/v6.0/Documentation/ABI/testing/sysfs-bus-pci#L344-L355\n",
      "2023-11-20 02:47:24.454944: I tensorflow/compiler/xla/stream_executor/cuda/cuda_gpu_executor.cc:995] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero. See more at https://github.com/torvalds/linux/blob/v6.0/Documentation/ABI/testing/sysfs-bus-pci#L344-L355\n",
      "2023-11-20 02:47:24.455057: I tensorflow/compiler/xla/stream_executor/cuda/cuda_gpu_executor.cc:995] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero. See more at https://github.com/torvalds/linux/blob/v6.0/Documentation/ABI/testing/sysfs-bus-pci#L344-L355\n",
      "2023-11-20 02:47:24.455142: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1636] Created device /job:localhost/replica:0/task:0/device:GPU:0 with 1124 MB memory:  -> device: 0, name: GRID A100D-40C, pci bus id: 0000:02:02.0, compute capability: 8.0\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns \n",
    "from sklearn.feature_extraction.text import CountVectorizer\n",
    "from sklearn.feature_extraction.text import TfidfTransformer\n",
    "from sklearn import feature_extraction, linear_model, model_selection, preprocessing\n",
    "from sklearn.metrics import accuracy_score\n",
    "from sklearn import metrics\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.pipeline import Pipeline\n",
    "import tensorflow as tf\n",
    "data = pd.read_csv(\"fakenews_data.csv\")\n",
    "data['text'] = data['text'].values.astype('U')\n",
    "# Split the data\n",
    "X_train,X_test,y_train,y_test = train_test_split(data['text'], data.target, test_size=0.2, random_state=42)\n",
    "#LSTM Model\n",
    "# calculating maximum sequence length\n",
    "def find_max_sequence_length(dataframe, column_name):\n",
    "    # Assuming the specified column contains sequences (e.g., sentences)\n",
    "    sequences = dataframe[column_name].tolist()\n",
    "\n",
    "    # Calculate the maximum sequence length\n",
    "    max_sequence_length = max(len(seq.split()) for seq in sequences)\n",
    "\n",
    "    return max_sequence_length\n",
    "\n",
    "max_length = find_max_sequence_length(data, 'text')\n",
    "import tensorflow as tf\n",
    "\n",
    "model = tf.keras.Sequential([\n",
    "    tf.keras.layers.Embedding(10000, 128, input_length=256),\n",
    "    tf.keras.layers.Bidirectional(tf.keras.layers.LSTM(128, return_sequences=True)),\n",
    "    tf.keras.layers.Bidirectional(tf.keras.layers.LSTM(64)),\n",
    "    tf.keras.layers.Dense(256, activation='relu'),\n",
    "    tf.keras.layers.BatchNormalization(),\n",
    "    tf.keras.layers.Dropout(0.5),\n",
    "    tf.keras.layers.Dense(1, activation='sigmoid')\n",
    "])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "d658e893",
   "metadata": {},
   "outputs": [],
   "source": [
    "from tensorflow.keras.preprocessing.text import Tokenizer\n",
    "tokenizer = Tokenizer(num_words=1000)\n",
    "tokenizer.fit_on_texts(X_train)\n",
    "X_train1 = tokenizer.texts_to_sequences(X_train)\n",
    "X_test1 = tokenizer.texts_to_sequences(X_test)\n",
    "X_train2 = tf.keras.preprocessing.sequence.pad_sequences(X_train1, padding='post', maxlen=256)\n",
    "X_test2 = tf.keras.preprocessing.sequence.pad_sequences(X_test1, padding='post', maxlen=256)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "8de5ddb0",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/10\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.10/dist-packages/keras/src/backend.py:5805: UserWarning: \"`binary_crossentropy` received `from_logits=True`, but the `output` argument was produced by a Sigmoid activation and thus does not represent logits. Was this intended?\n",
      "  output, from_logits = _get_logits(\n",
      "2023-11-20 02:47:41.136343: I tensorflow/compiler/xla/stream_executor/cuda/cuda_dnn.cc:432] Loaded cuDNN version 8905\n",
      "2023-11-20 02:47:41.229102: I tensorflow/compiler/xla/stream_executor/cuda/cuda_blas.cc:625] TensorFloat-32 will be used for the matrix multiplication. This will only be logged once.\n",
      "2023-11-20 02:47:41.265298: I tensorflow/compiler/xla/service/service.cc:168] XLA service 0x7f96d994cd70 initialized for platform CUDA (this does not guarantee that XLA will be used). Devices:\n",
      "2023-11-20 02:47:41.265336: I tensorflow/compiler/xla/service/service.cc:176]   StreamExecutor device (0): GRID A100D-40C, Compute Capability 8.0\n",
      "2023-11-20 02:47:41.270826: I tensorflow/compiler/mlir/tensorflow/utils/dump_mlir_util.cc:255] disabling MLIR crash reproducer, set env var `MLIR_CRASH_REPRODUCER_DIRECTORY` to enable.\n",
      "2023-11-20 02:47:41.401348: I ./tensorflow/compiler/jit/device_compiler.h:186] Compiled cluster using XLA!  This line is logged at most once for the lifetime of the process.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1198/1198 [==============================] - 77s 60ms/step - loss: 0.0544 - accuracy: 0.9828 - val_loss: 0.0102 - val_accuracy: 0.9969\n",
      "Epoch 2/10\n",
      "1198/1198 [==============================] - 47s 39ms/step - loss: 0.0100 - accuracy: 0.9974 - val_loss: 0.0072 - val_accuracy: 0.9984\n",
      "Epoch 3/10\n",
      "1198/1198 [==============================] - 47s 39ms/step - loss: 0.0063 - accuracy: 0.9981 - val_loss: 0.0075 - val_accuracy: 0.9988\n",
      "Epoch 4/10\n",
      "1198/1198 [==============================] - 45s 38ms/step - loss: 0.0050 - accuracy: 0.9986 - val_loss: 0.0081 - val_accuracy: 0.9984\n"
     ]
    }
   ],
   "source": [
    "early_stop = tf.keras.callbacks.EarlyStopping(monitor='val_loss', patience=2, restore_best_weights=True)\n",
    "model.compile(\n",
    "    loss=tf.keras.losses.BinaryCrossentropy(from_logits=True),\n",
    "    optimizer=tf.keras.optimizers.Adam(learning_rate=1e-4),\n",
    "    metrics=['accuracy']\n",
    ")\n",
    "\n",
    "history = model.fit(\n",
    "    X_train2, y_train,\n",
    "    epochs=10,\n",
    "    batch_size=30,\n",
    "    validation_data=(X_test2, y_test),\n",
    "    callbacks=[early_stop]\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "71d35b30",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "c19ff4ab",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package stopwords to /root/nltk_data...\n",
      "[nltk_data]   Package stopwords is already up-to-date!\n",
      "[nltk_data] Downloading package punkt to /root/nltk_data...\n",
      "[nltk_data]   Package punkt is already up-to-date!\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from nltk.tokenize import word_tokenize\n",
    "from nltk.corpus import stopwords\n",
    "from gensim.models import Word2Vec\n",
    "import tensorflow as tf\n",
    "import string\n",
    "\n",
    "from nltk.tokenize import word_tokenize\n",
    "from nltk.corpus import stopwords\n",
    "import string\n",
    "\n",
    "def punctuation_removal(text):\n",
    "    # Convert the NumPy array to a list of strings\n",
    "    text_list = [str(item) for item in text]\n",
    "    # Join the list into a string\n",
    "    text_str = ' '.join(text_list)\n",
    "\n",
    "    # Remove punctuation\n",
    "    all_list = [char for char in text_str if char not in string.punctuation]\n",
    "    clean_str = ''.join(all_list)\n",
    "    \n",
    "    return clean_str\n",
    "\n",
    "def tokenize_text(input_text):\n",
    "    # Remove punctuation\n",
    "    clean_str = punctuation_removal(input_text)\n",
    "\n",
    "    # Remove stopwords and tokenize\n",
    "    stop = stopwords.words('english')\n",
    "    tokens = word_tokenize(clean_str)\n",
    "    tokens = [word for word in tokens if word.lower() not in stop]\n",
    "\n",
    "    return tokens\n",
    "\n",
    "#to calculate to emotion score\n",
    "def calculate_emotion_score(tokens, eemotion_words):\n",
    "    total_score = 0\n",
    "    count = 0\n",
    "    for word in tokens:\n",
    "        if word in eemotion_words:\n",
    "            total_score += eemotion_words[word]\n",
    "            count += 1\n",
    "    return total_score / max(1,count)\n",
    "\n",
    "#code to classify emotions \n",
    "def classify_emotion(tokens, eemotion_words, word2vec_model):\n",
    "    emotion_score = calculate_emotion_score(tokens, eemotion_words)\n",
    "    \n",
    "    # Use the 'wv' attribute for Word2Vec model\n",
    "    token_vectors = [word2vec_model.wv[word] for word in tokens if word in word2vec_model.wv]\n",
    "\n",
    "    mean_vector = np.mean(token_vectors, axis=0)\n",
    "    if emotion_score >= 0.8:\n",
    "        return \"Very Emotional Triggering\"\n",
    "    elif emotion_score >= 0.6:\n",
    "        return \"Emotionally Triggering\"\n",
    "    elif emotion_score >= 0.4:\n",
    "        return \"Neutral\"\n",
    "    elif emotion_score >= 0.2:\n",
    "        return \"Slightly Triggering\"\n",
    "    else:\n",
    "        return \"Safe Text\"\n",
    "\n",
    "# Define LSTM model\n",
    "def create_lstm_model(input_length):\n",
    "    model = tf.keras.Sequential([\n",
    "        tf.keras.layers.Embedding(10000, 128, input_length=input_length),\n",
    "        tf.keras.layers.Bidirectional(tf.keras.layers.LSTM(128, return_sequences=True)),\n",
    "        tf.keras.layers.Bidirectional(tf.keras.layers.LSTM(64)),\n",
    "        tf.keras.layers.Dense(256, activation='relu'),\n",
    "        tf.keras.layers.BatchNormalization(),\n",
    "        tf.keras.layers.Dropout(0.5),\n",
    "        tf.keras.layers.Dense(1, activation='sigmoid')\n",
    "    ])\n",
    "    \n",
    "    return model\n",
    "\n",
    "# Function to preprocess input text\n",
    "def preprocess_input(text):\n",
    "    # Remove punctuation\n",
    "    clean_str = punctuation_removal(text)\n",
    "\n",
    "    # Remove stopwords\n",
    "    stop = stopwords.words('english')\n",
    "    clean_text = ' '.join([word for word in clean_str.split() if word not in stop])\n",
    "\n",
    "    return clean_text\n",
    "\n",
    "# Function to classify news and emotional intensity\n",
    "def classify_news_and_emotion(input_text, lstm_model, emotion_words, word2vec_model):\n",
    "    # Preprocess input text\n",
    "    cleaned_text = preprocess_input(input_text)\n",
    "    # Tokenize and pad the sequence\n",
    "    input_sequence = tokenize_text(cleaned_text)\n",
    "    padded_sequence = tf.keras.preprocessing.sequence.pad_sequences([input_sequence], padding='post', maxlen=256)\n",
    "    # Predict using LSTM model\n",
    "    lstm_prediction = lstm_model.predict(padded_sequence)\n",
    "    # Classify news as \"fake news\" or \"real news\"\n",
    "    news_category = \"fake news\" if lstm_prediction >= 0.5 else \"real news\"\n",
    "    # Tokenize the input text\n",
    "    input_tokens = cleaned_text.split()\n",
    "    # Calculate emotional intensity using fuzzy logic\n",
    "    emotion_intensity = classify_emotion(input_tokens, emotion_words, word2vec_model)\n",
    "    return news_category, emotion_intensity\n",
    "\n",
    "import nltk\n",
    "nltk.download('stopwords')\n",
    "nltk.download('punkt')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6f1fd67b",
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "from tensorflow.keras.preprocessing.text import Tokenizer\n",
    "from tensorflow.keras.preprocessing.sequence import pad_sequences\n",
    "\n",
    "negative_words = {\n",
    "    'sad': 0.8, 'angry': 0.7, 'frustrated': 0.6, 'disappointed': 0.7,\n",
    "    'upset': 0.8, 'miserable': 0.9, 'depressed': 0.8, 'dismal': 0.7,\n",
    "    'unhappy': 0.6, 'troubled': 0.7, 'grim': 0.8, 'gloomy': 0.7,\n",
    "    'distraught': 0.7, 'weary': 0.6, 'pessimistic': 0.7, 'annoyed': 0.6,\n",
    "    'irritated': 0.7, 'hostile': 0.8, 'bitter': 0.7, 'resentful': 0.6,\n",
    "    'discouraged': 0.7, 'hopeless': 0.8, 'dejected': 0.7, 'sorrowful': 0.6,\n",
    "    'overwhelmed': 0.8, 'exhausted': 0.7, 'numb': 0.6, 'dreadful': 0.8,\n",
    "    'unpleasant': 0.7, 'apprehensive': 0.6, 'repulsive': 0.7, 'hateful': 0.8,\n",
    "    'detestable': 0.7, 'abominable': 0.6, 'abhorrent': 0.7, 'repugnant': 0.8,\n",
    "    'disgusted': 0.7, 'revolting': 0.6, 'disheartened': 0.7, 'discontented': 0.8,\n",
    "    'displeased': 0.7, 'disgruntled': 0.6, 'mournful': 0.7, 'wretched': 0.8,\n",
    "    'desolate': 0.7, 'forlorn': 0.6, 'grief-stricken': 0.7, 'anguished': 0.8,\n",
    "    'desperate': 0.7, 'woeful': 0.6, 'woebegone': 0.7, 'melancholy': 0.8,\n",
    "    'pitiful': 0.7, 'pathetic': 0.6, 'heartrending': 0.7, 'agonizing': 0.8,\n",
    "    'worn-out': 0.6, 'fatigued': 0.7, 'drained': 0.6, 'exasperated': 0.7,\n",
    "    'irksome': 0.6, 'enraged': 0.8, 'infuriated': 0.7, 'livid': 0.8,\n",
    "    'indignant': 0.7, 'outraged': 0.8, 'incensed': 0.7, 'riled': 0.6,\n",
    "    'troubled': 0.7, 'dismayed': 0.8, 'crestfallen': 0.7, 'disillusioned': 0.6,\n",
    "    'disgruntled': 0.7, 'displeased': 0.6, 'irritable': 0.7, 'querulous': 0.6,\n",
    "    'cross': 0.7, 'discontented': 0.6, 'disgusted': 0.7, 'revolted': 0.6,\n",
    "    'abhorrent': 0.7, 'repellent': 0.6, 'disastrous': 0.8, 'woeful': 0.7,\n",
    "    'mournful': 0.8, 'tragic': 0.7, 'grievous': 0.8, 'melancholic': 0.7,\n",
    "    'heartbroken': 0.8, 'crestfallen': 0.7, 'downcast': 0.6, 'unfortunate': 0.7,\n",
    "    'unlucky': 0.6, 'unhappy': 0.7, 'forlorn': 0.6, 'gloomy': 0.7,\n",
    "    'dreary': 0.6, 'bleak': 0.7, 'desperate': 0.6, 'hopeless': 0.7,\n",
    "    'dismal': 0.6, 'pessimistic': 0.7, 'fatalistic': 0.6, 'unfavorable': 0.7,\n",
    "    'adverse': 0.6, 'hostile': 0.7, 'antagonistic': 0.6, 'inhospitable': 0.7,\n",
    "    'unsympathetic': 0.6, 'callous': 0.7, 'indifferent': 0.6, 'apathetic': 0.7,\n",
    "    'listless': 0.6, 'uninterested': 0.7, 'bored': 0.6, 'weary': 0.7,\n",
    "    'tired': 0.6, 'exhausted': 0.7, 'fatigued': 0.6, 'drained': 0.7,\n",
    "    'weary': 0.6, 'burned-out': 0.7, 'worn-out': 0.6, 'lethargic': 0.7,\n",
    "    'sluggish': 0.6, 'lifeless': 0.7, 'apathetic': 0.6, 'indifferent': 0.7,\n",
    "    'unresponsive': 0.6, 'insensitive': 0.7, 'cold': 0.6, 'aloof': 0.7,\n",
    "    'detached': 0.6, 'unemotional': 0.7, 'stoic': 0.6, 'expressionless': 0.7,\n",
    "    'robotic': 0.6, 'mechanical': 0.7\n",
    "}\n",
    "\n",
    "trigger_words = {\n",
    "    'death': 0.9, 'shot' : 0.9,'failure': 0.8, 'accident': 0.7, 'tragedy': 0.8,\n",
    "    'disaster': 0.9, 'crisis': 0.8, 'heartbreak': 0.7, 'calamity': 0.8,\n",
    "    'horrific': 0.9, 'devastating': 0.8, 'trauma': 0.7, 'nightmare': 0.8,\n",
    "    'catastrophe': 0.8, 'calamitous': 0.7, 'cataclysmic': 0.8, 'apocalyptic': 0.7,\n",
    "    'devastation': 0.8, 'ruin': 0.7, 'carnage': 0.8, 'destruction': 0.7,\n",
    "    'misfortune': 0.8, 'mishap': 0.7, 'catastrophic': 0.8, 'accidental': 0.7,\n",
    "    'fatal': 0.8, 'cruel': 0.7, 'harmful': 0.8, 'perilous': 0.7,\n",
    "    'threatening': 0.8, 'menacing': 0.7, 'ominous': 0.8, 'foreboding': 0.7,\n",
    "    'dreadful': 0.8, 'fateful': 0.7, 'unfortunate': 0.8, 'troublesome': 0.7,\n",
    "    'dire': 0.8, 'unlucky': 0.7, 'unfavorable': 0.8, 'unfortunate': 0.7,\n",
    "    'hazardous': 0.8, 'dangerous': 0.7, 'threatening': 0.8, 'ominous': 0.7,\n",
    "    'horrifying': 0.8, 'terrifying': 0.7, 'shocking': 0.8, 'appalling': 0.7,\n",
    "    'dreadful': 0.8, 'ghastly': 0.7, 'spine-chilling': 0.8, 'hair-raising': 0.7,\n",
    "    'catastrophe': 0.8, 'calamitous': 0.7, 'cataclysmic': 0.8, 'apocalyptic': 0.7,\n",
    "    'devastation': 0.8, 'ruin': 0.7, 'carnage': 0.8, 'destruction': 0.7,'terrorist' : 0.8, \n",
    "    'misfortune': 0.8, 'mishap': 0.7, 'catastrophic': 0.8, 'accidental': 0.7,\n",
    "    'fatal': 0.8, 'cruel': 0.7, 'harmful': 0.8, 'perilous': 0.7,\n",
    "    'threatening': 0.8, 'menacing': 0.7, 'ominous': 0.8, 'foreboding': 0.7,\n",
    "    'dreadful': 0.8, 'fateful': 0.7, 'unfortunate': 0.8, 'troublesome': 0.7,\n",
    "    'dire': 0.8, 'unlucky': 0.7, 'unfavorable': 0.8, 'unfortunate': 0.7,\n",
    "    'hazardous': 0.8, 'dangerous': 0.7, 'threatening': 0.8, 'ominous': 0.7,\n",
    "    'horrifying': 0.8, 'terrifying': 0.7, 'shocking': 0.8, 'appalling': 0.7,\n",
    "    'dreadful': 0.8, 'ghastly': 0.7, 'spine-chilling': 0.8, 'hair-raising': 0.7,\n",
    "    'abysmal': 0.8, 'bleak': 0.7, 'ghastly': 0.8, 'grim': 0.7,\n",
    "    'heartbreaking': 0.8, 'unbearable': 0.7, 'gut-wrenching': 0.8, 'disconcerting': 0.7,\n",
    "    'perturbing': 0.8, 'unsettling': 0.7, 'alarming': 0.8, 'disquieting': 0.7,\n",
    "    'unnerving': 0.8, 'foreboding': 0.7, 'threatening': 0.8, 'menacing': 0.7,\n",
    "    'hostile': 0.8, 'noxious': 0.7, 'pernicious': 0.8, 'destructive': 0.7,\n",
    "    'debilitating': 0.8, 'ruinous': 0.7, 'catastrophically': 0.8, 'tragic': 0.7,\n",
    "    'devastating': 0.8, 'ruinous': 0.7\n",
    "}\n",
    "\n",
    "df = pd.read_csv(\"fakenews_data.csv\")\n",
    "# Convert 'text' column to strings, handling potential NaN values\n",
    "df['text'] = df['text'].astype(str)\n",
    "sentences = df['text'].values\n",
    "\n",
    "# Create and train Word2Vec model\n",
    "word2vec_model = Word2Vec(sentences, vector_size=100, window=5, min_count=1, sg=0)\n",
    "# Save the trained Word2Vec model (optional)\n",
    "word2vec_model.save(\"word2vec_model.model\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8bed935f",
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "# Example usage\n",
    "input_tweet = input(\"Enter your tweet: \")\n",
    "tokenizer = Tokenizer(num_words=1000)\n",
    "tokenizer.fit_on_texts([input_tweet])\n",
    "\n",
    "lstm_model = model\n",
    "\n",
    "# Tokenize the input text\n",
    "sequences = tokenizer.texts_to_matrix([input_tweet], mode='count')\n",
    "\n",
    "# Pad the sequences\n",
    "padded_sequences = pad_sequences(sequences, maxlen=256, padding='post')\n",
    "\n",
    "# Convert the padded_sequences to a list\n",
    "padded_sequences_list = [padded_sequences[0]]\n",
    "emotion_words = {**negative_words, **trigger_words}\n",
    "\n",
    "# Call the function to classify news and emotional intensity\n",
    "news_category, emotion_intensity = classify_news_and_emotion(padded_sequences_list, lstm_model, emotion_words, word2vec_model)\n",
    "\n",
    "# Print the results\n",
    "print(\"News Category:\", news_category)\n",
    "print(\"Emotion Intensity:\", emotion_intensity)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c9a1e73c",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
